{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7852bc3d-0660-49cd-a02c-14105ccb6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geneformer\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import loompy\n",
    "\n",
    "# The purpose of this notebook is to prepare our data for tokenization and then tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a60c29-4104-4b3e-b393-5088149c85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/u/scratch/s/schhina/geneformer_raw_data\"\n",
    "output_path = \"/u/scratch/s/schhina/geneformer_tokenized_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61193b4b-6a41-420e-b011-46852b9be8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 47726 × 60725\n",
       "    obs: 'stimulation', 'cd_status'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = ad.read_h5ad(\"/u/scratch/s/schhina/labeled_t_cell_data.h5ad\")\n",
    "# adata.write_loom(\"/u/scratch/s/schhina/geneformer_raw_data/labeled_t_cell_data.loom\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3b2d2d0-aa89-478b-9814-b2408b56a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60725, 47726)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A loom file is basically a transpose of a h5ad file (which is what our data is currently stored in)\n",
    "\n",
    "ds = loompy.connect(\"/u/scratch/s/schhina/geneformer_raw_data/labeled_t_cell_data.loom\") # Open a loom file\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff64cb2-b9ca-4d45-a979-ff8b0d95a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To tokenize we need the n_counts and ensembl_id fields\n",
    "\n",
    "ds.ca['n_counts'] = [np.sum(ds[:, i]) for i in np.arange(ds.shape[1])] # Add a count column to loom file\n",
    "ds.ra['ensembl_id'] = [(s.split('.')[0]) for s in ds.ra.Accession] # Add an ensembl_id row to loom file\n",
    "del ds.ra['Accession'] # Remove Accession row\n",
    "ds.close() # Close the loom file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb63688-df7a-41af-ad4b-d33e9142a667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tk = TranscriptomeTokenizer({'stimulation': 'stimulation'}, nproc=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa7e40d-36ba-459f-a26a-8a74ae93517f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing /u/scratch/s/schhina/geneformer_raw_data/labeled_t_cell_data.loom\n",
      "/u/scratch/s/schhina/geneformer_raw_data/labeled_t_cell_data.loom has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "Creating dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408fcb5fb8604dc7a5c48e7d0b8a6f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=16):   0%|          | 0/47726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634922300d044823923291ad64140d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/47726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tk.tokenize_data(data_path, output_path, \"Q_data_\", file_format=\"loom\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer_env",
   "language": "python",
   "name": "geneformer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
